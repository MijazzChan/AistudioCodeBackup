{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看当前挂载的数据集目录, 该目录下的变更重启环境后会自动还原\n",
    "# View dataset directory. This directory will be recovered automatically after resetting environment. \n",
    "!ls /home/aistudio/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 查看工作区文件, 该目录下的变更将会持久保存. 请及时清理不必要的文件, 避免加载过慢.\n",
    "# View personal work directory. All changes under this directory will be kept even after reset. Please clean unnecessary files in time to speed up environment loading.\n",
    "!ls /home/aistudio/work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "请点击[此处](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576)查看本环境基本用法.  <br>\n",
    "Please click [here ](https://ai.baidu.com/docs#/AIStudio_Project_Notebook/a38e5576) for more detailed instructions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 第五次作业\n",
    "---\n",
    "2017326603075  陈浩骏  2017326603075\n",
    "\n",
    "## 题1\n",
    "+ 添加了两个Linear层，与一层Relu激活函数之后，回归拟合结果的误差相差大的频率变小了。在使用单层的时候，因为拟合数据的batch也是随机的，会出现拟合测试与实际相差超过50%，但是添加层之后，虽然还有极低出现的频率，但是大lost减少了很多。\n",
    "+ 13 -> 8 -> 4 -> 1 (F C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single Layer FC Linear Model\n",
      "Inference result is [[22.396992]], the corresponding label is 19.7\n"
     ]
    }
   ],
   "source": [
    "# 共两题：\r\n",
    "# 1 请将房价预测修改为多层带激活函数的全联接模型，并比较与线性回归模型的效果有什么不同\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import paddle.fluid.dygraph as dygraph\r\n",
    "from paddle.fluid.dygraph import Linear\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import random\r\n",
    "\r\n",
    "def load_data():\r\n",
    "    # 从文件导入数据\r\n",
    "    datafile = './work/housing.data.csv'\r\n",
    "    data = np.fromfile(datafile, sep=' ')\r\n",
    "\r\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\r\n",
    "    feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \\\r\n",
    "                      'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\r\n",
    "    feature_num = len(feature_names)\r\n",
    "\r\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\r\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\r\n",
    "\r\n",
    "    # 将原数据集拆分成训练集和测试集\r\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\r\n",
    "    # 测试集和训练集必须是没有交集的\r\n",
    "    ratio = 0.8\r\n",
    "    offset = int(data.shape[0] * ratio)\r\n",
    "    training_data = data[:offset]\r\n",
    "\r\n",
    "    # 计算train数据集的最大值，最小值，平均值\r\n",
    "    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), \\\r\n",
    "                                 training_data.sum(axis=0) / training_data.shape[0]\r\n",
    "    \r\n",
    "    # 记录数据的归一化参数，在预测时对数据做归一化\r\n",
    "    global max_values\r\n",
    "    global min_values\r\n",
    "    global avg_values\r\n",
    "    max_values = maximums\r\n",
    "    min_values = minimums\r\n",
    "    avg_values = avgs\r\n",
    "\r\n",
    "    # 对数据进行归一化处理\r\n",
    "    for i in range(feature_num):\r\n",
    "        #print(maximums[i], minimums[i], avgs[i])\r\n",
    "        data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])\r\n",
    "\r\n",
    "    # 训练集和测试集的划分比例\r\n",
    "    training_data = data[:offset]\r\n",
    "    test_data = data[offset:]\r\n",
    "    return training_data, test_data\r\n",
    "\r\n",
    "print('Single Layer FC Linear Model')\r\n",
    "class Regressor(fluid.dygraph.Layer):\r\n",
    "    def __init__(self, name_scope):\r\n",
    "        super(Regressor, self).__init__(name_scope)\r\n",
    "        name_scope = self.full_name()\r\n",
    "        # 定义一层全连接层，输出维度是1，激活函数为None，即不使用激活函数\r\n",
    "        self.fc = Linear(input_dim=13, output_dim=1, act=None)\r\n",
    "    \r\n",
    "    # 网络的前向计算函数\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.fc(inputs)\r\n",
    "        return x\r\n",
    "\r\n",
    "# 定义飞桨动态图的工作环境\r\n",
    "with fluid.dygraph.guard():\r\n",
    "    # 声明定义好的线性回归模型\r\n",
    "    model = Regressor(\"Regressor\")\r\n",
    "    # 开启模型训练模式\r\n",
    "    model.train()\r\n",
    "    # 加载数据\r\n",
    "    training_data, test_data = load_data()\r\n",
    "    # 定义优化算法，这里使用随机梯度下降-SGD\r\n",
    "    # 学习率设置为0.01\r\n",
    "    opt = fluid.optimizer.SGD(learning_rate=0.01, parameter_list=model.parameters())\r\n",
    "\r\n",
    "# 启动训练\r\n",
    "with dygraph.guard(fluid.CPUPlace()):\r\n",
    "    EPOCH_NUM = 10   # 设置外层循环次数\r\n",
    "    BATCH_SIZE = 10  # 设置batch大小\r\n",
    "    \r\n",
    "    # 定义外层循环\r\n",
    "    for epoch_id in range(EPOCH_NUM):\r\n",
    "        # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\r\n",
    "        np.random.shuffle(training_data)\r\n",
    "        # 将训练数据进行拆分，每个batch包含10条数据\r\n",
    "        mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\r\n",
    "        # 定义内层循环\r\n",
    "        for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "            x = np.array(mini_batch[:, :-1]).astype('float32') # 获得当前批次训练数据\r\n",
    "            y = np.array(mini_batch[:, -1:]).astype('float32') # 获得当前批次训练标签（真实房价）\r\n",
    "            # 将numpy数据转为飞桨动态图variable形式\r\n",
    "            house_features = dygraph.to_variable(x)\r\n",
    "            prices = dygraph.to_variable(y)\r\n",
    "            \r\n",
    "            # 前向计算\r\n",
    "            predicts = model(house_features)\r\n",
    "            \r\n",
    "            # 计算损失\r\n",
    "            loss = fluid.layers.square_error_cost(predicts, label=prices)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "            if iter_id%20==0:\r\n",
    "                # print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, iter_id, avg_loss.numpy()))\r\n",
    "                pass\r\n",
    "            \r\n",
    "            # 反向传播\r\n",
    "            avg_loss.backward()\r\n",
    "            # 最小化loss,更新参数\r\n",
    "            opt.minimize(avg_loss)\r\n",
    "            # 清除梯度\r\n",
    "            model.clear_gradients()\r\n",
    "    # 保存模型\r\n",
    "    fluid.save_dygraph(model.state_dict(), 'LR_model')\r\n",
    "\r\n",
    "def load_one_example(data_dir):\r\n",
    "    f = open(data_dir, 'r')\r\n",
    "    datas = f.readlines()\r\n",
    "    # 选择倒数第10条数据用于测试\r\n",
    "    tmp = datas[-10]\r\n",
    "    tmp = tmp.strip().split()\r\n",
    "    one_data = [float(v) for v in tmp]\r\n",
    "\r\n",
    "    # 对数据进行归一化处理\r\n",
    "    for i in range(len(one_data)-1):\r\n",
    "        one_data[i] = (one_data[i] - avg_values[i]) / (max_values[i] - min_values[i])\r\n",
    "\r\n",
    "    data = np.reshape(np.array(one_data[:-1]), [1, -1]).astype(np.float32)\r\n",
    "    label = one_data[-1]\r\n",
    "    return data, label\r\n",
    "\r\n",
    "with dygraph.guard():\r\n",
    "    # 参数为保存模型参数的文件地址\r\n",
    "    model_dict, _ = fluid.load_dygraph('LR_model')\r\n",
    "    model.load_dict(model_dict)\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    # 参数为数据集的文件地址\r\n",
    "    test_data, label = load_one_example('./work/housing.data.csv')\r\n",
    "    # 将数据转为动态图的variable格式\r\n",
    "    test_data = dygraph.to_variable(test_data)\r\n",
    "    results = model(test_data)\r\n",
    "\r\n",
    "    # 对结果做反归一化处理\r\n",
    "    results = results * (max_values[-1] - min_values[-1]) + avg_values[-1]\r\n",
    "    print(\"Inference result is {}, the corresponding label is {}\".format(results.numpy(), label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi Layer FC Linear Model\n",
      "Inference result is [[21.478346]], the corresponding label is 19.7\n"
     ]
    }
   ],
   "source": [
    "\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "import paddle.fluid.dygraph as dygraph\r\n",
    "from paddle.fluid.dygraph import Linear\r\n",
    "import numpy as np\r\n",
    "import os\r\n",
    "import random\r\n",
    "\r\n",
    "def load_data():\r\n",
    "    # 从文件导入数据\r\n",
    "    datafile = './work/housing.data.csv'\r\n",
    "    data = np.fromfile(datafile, sep=' ')\r\n",
    "\r\n",
    "    # 每条数据包括14项，其中前面13项是影响因素，第14项是相应的房屋价格中位数\r\n",
    "    feature_names = [ 'CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', \\\r\n",
    "                      'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV' ]\r\n",
    "    feature_num = len(feature_names)\r\n",
    "\r\n",
    "    # 将原始数据进行Reshape，变成[N, 14]这样的形状\r\n",
    "    data = data.reshape([data.shape[0] // feature_num, feature_num])\r\n",
    "\r\n",
    "    # 将原数据集拆分成训练集和测试集\r\n",
    "    # 这里使用80%的数据做训练，20%的数据做测试\r\n",
    "    # 测试集和训练集必须是没有交集的\r\n",
    "    ratio = 0.8\r\n",
    "    offset = int(data.shape[0] * ratio)\r\n",
    "    training_data = data[:offset]\r\n",
    "\r\n",
    "    # 计算train数据集的最大值，最小值，平均值\r\n",
    "    maximums, minimums, avgs = training_data.max(axis=0), training_data.min(axis=0), \\\r\n",
    "                                 training_data.sum(axis=0) / training_data.shape[0]\r\n",
    "    \r\n",
    "    # 记录数据的归一化参数，在预测时对数据做归一化\r\n",
    "    global max_values\r\n",
    "    global min_values\r\n",
    "    global avg_values\r\n",
    "    max_values = maximums\r\n",
    "    min_values = minimums\r\n",
    "    avg_values = avgs\r\n",
    "\r\n",
    "    # 对数据进行归一化处理\r\n",
    "    for i in range(feature_num):\r\n",
    "        #print(maximums[i], minimums[i], avgs[i])\r\n",
    "        data[:, i] = (data[:, i] - avgs[i]) / (maximums[i] - minimums[i])\r\n",
    "\r\n",
    "    # 训练集和测试集的划分比例\r\n",
    "    training_data = data[:offset]\r\n",
    "    test_data = data[offset:]\r\n",
    "    return training_data, test_data\r\n",
    "\r\n",
    "print('Multi Layer FC Linear Model')\r\n",
    "class Regressor(fluid.dygraph.Layer):\r\n",
    "    def __init__(self, name_scope):\r\n",
    "        super(Regressor, self).__init__(name_scope)\r\n",
    "        name_scope = self.full_name()\r\n",
    "        # 定义一层全连接层，输出维度是1，激活函数为None，即不使用激活函数\r\n",
    "        self.fc = Linear(input_dim=13, output_dim=8, act='relu')\r\n",
    "        self.sc = Linear(input_dim=8, output_dim=4, act='relu')\r\n",
    "        self.tc = Linear(input_dim=4, output_dim=1, act=None)\r\n",
    "    \r\n",
    "    # 网络的前向计算函数\r\n",
    "    def forward(self, inputs):\r\n",
    "        x = self.fc(inputs)\r\n",
    "        x = self.sc(x)\r\n",
    "        x = self.tc(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "# 定义飞桨动态图的工作环境\r\n",
    "with fluid.dygraph.guard():\r\n",
    "    # 声明定义好的线性回归模型\r\n",
    "    model = Regressor(\"Regressor\")\r\n",
    "    # 开启模型训练模式\r\n",
    "    model.train()\r\n",
    "    # 加载数据\r\n",
    "    training_data, test_data = load_data()\r\n",
    "    # 定义优化算法，这里使用随机梯度下降-SGD\r\n",
    "    # 学习率设置为0.01\r\n",
    "    opt = fluid.optimizer.SGD(learning_rate=0.01, parameter_list=model.parameters())\r\n",
    "\r\n",
    "# 启动训练\r\n",
    "with dygraph.guard(fluid.CPUPlace()):\r\n",
    "    EPOCH_NUM = 10   # 设置外层循环次数\r\n",
    "    BATCH_SIZE = 10  # 设置batch大小\r\n",
    "    \r\n",
    "    # 定义外层循环\r\n",
    "    for epoch_id in range(EPOCH_NUM):\r\n",
    "        # 在每轮迭代开始之前，将训练数据的顺序随机的打乱\r\n",
    "        np.random.shuffle(training_data)\r\n",
    "        # 将训练数据进行拆分，每个batch包含10条数据\r\n",
    "        mini_batches = [training_data[k:k+BATCH_SIZE] for k in range(0, len(training_data), BATCH_SIZE)]\r\n",
    "        # 定义内层循环\r\n",
    "        for iter_id, mini_batch in enumerate(mini_batches):\r\n",
    "            x = np.array(mini_batch[:, :-1]).astype('float32') # 获得当前批次训练数据\r\n",
    "            y = np.array(mini_batch[:, -1:]).astype('float32') # 获得当前批次训练标签（真实房价）\r\n",
    "            # 将numpy数据转为飞桨动态图variable形式\r\n",
    "            house_features = dygraph.to_variable(x)\r\n",
    "            prices = dygraph.to_variable(y)\r\n",
    "            \r\n",
    "            # 前向计算\r\n",
    "            predicts = model(house_features)\r\n",
    "            \r\n",
    "            # 计算损失\r\n",
    "            loss = fluid.layers.square_error_cost(predicts, label=prices)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "            if iter_id%20==0:\r\n",
    "                # print(\"epoch: {}, iter: {}, loss is: {}\".format(epoch_id, iter_id, avg_loss.numpy()))\r\n",
    "                pass\r\n",
    "            \r\n",
    "            # 反向传播\r\n",
    "            avg_loss.backward()\r\n",
    "            # 最小化loss,更新参数\r\n",
    "            opt.minimize(avg_loss)\r\n",
    "            # 清除梯度\r\n",
    "            model.clear_gradients()\r\n",
    "    # 保存模型\r\n",
    "    fluid.save_dygraph(model.state_dict(), 'LR_model')\r\n",
    "\r\n",
    "def load_one_example(data_dir):\r\n",
    "    f = open(data_dir, 'r')\r\n",
    "    datas = f.readlines()\r\n",
    "    # 选择倒数第10条数据用于测试\r\n",
    "    tmp = datas[-10]\r\n",
    "    tmp = tmp.strip().split()\r\n",
    "    one_data = [float(v) for v in tmp]\r\n",
    "\r\n",
    "    # 对数据进行归一化处理\r\n",
    "    for i in range(len(one_data)-1):\r\n",
    "        one_data[i] = (one_data[i] - avg_values[i]) / (max_values[i] - min_values[i])\r\n",
    "\r\n",
    "    data = np.reshape(np.array(one_data[:-1]), [1, -1]).astype(np.float32)\r\n",
    "    label = one_data[-1]\r\n",
    "    return data, label\r\n",
    "\r\n",
    "with dygraph.guard():\r\n",
    "    # 参数为保存模型参数的文件地址\r\n",
    "    model_dict, _ = fluid.load_dygraph('LR_model')\r\n",
    "    model.load_dict(model_dict)\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    # 参数为数据集的文件地址\r\n",
    "    test_data, label = load_one_example('./work/housing.data.csv')\r\n",
    "    # 将数据转为动态图的variable格式\r\n",
    "    test_data = dygraph.to_variable(test_data)\r\n",
    "    results = model(test_data)\r\n",
    "\r\n",
    "    # 对结果做反归一化处理\r\n",
    "    results = results * (max_values[-1] - min_values[-1]) + avg_values[-1]\r\n",
    "    print(\"Inference result is {}, the corresponding label is {}\".format(results.numpy(), label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 题2\n",
    "+ 更改guard传入的`fluid.CPUPlace()`为`fluid.CUDAPlace(0)`\n",
    "<br/>\n",
    "因为环境算力卡为Nvidia下，加速单元为cuda核，0为卡位参数，单卡即为0\n",
    "---\n",
    "时间（秒）由258.6152288913727 降至 28.782493352890015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-03-27 14:32:11,283-INFO: font search path ['/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/ttf', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/afm', '/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/mpl-data/fonts/pdfcorefonts']\n",
      "2020-03-27 14:32:11,718-INFO: generated new fontManager\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mnist dataset from ./work/mnist.json.gz ......\n",
      "epoch: 0, batch: 0, loss is: [31.022549]\n",
      "epoch: 0, batch: 200, loss is: [2.29561]\n",
      "epoch: 0, batch: 400, loss is: [1.6355603]\n",
      "epoch: 1, batch: 0, loss is: [3.4866533]\n",
      "epoch: 1, batch: 200, loss is: [1.7562844]\n",
      "epoch: 1, batch: 400, loss is: [2.2377365]\n",
      "epoch: 2, batch: 0, loss is: [1.7528464]\n",
      "epoch: 2, batch: 200, loss is: [1.4022287]\n",
      "epoch: 2, batch: 400, loss is: [0.85900605]\n",
      "epoch: 3, batch: 0, loss is: [1.4251589]\n",
      "epoch: 3, batch: 200, loss is: [1.3207119]\n",
      "epoch: 3, batch: 400, loss is: [2.060235]\n",
      "epoch: 4, batch: 0, loss is: [1.1186672]\n",
      "epoch: 4, batch: 200, loss is: [1.7002825]\n",
      "epoch: 4, batch: 400, loss is: [1.0438666]\n",
      "Time 258.6152288913727\n"
     ]
    }
   ],
   "source": [
    "#2 学习视频，修改以下代码使其能正常执行（部分代码缺失），并修改卷积核个数，或者增加卷积层树，修改激活函数等方式找到你认为最合适的超参\n",
    "#2.2 修改代码使其能在GPU上执行，并比较与CPU上执行的时间差异\n",
    "import os\n",
    "import random\n",
    "import paddle\n",
    "import paddle.fluid as fluid\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from time import *\n",
    "\n",
    "import gzip\n",
    "import json\n",
    "\n",
    "# 定义数据集读取器\n",
    "def load_data(mode='train'):\n",
    "\n",
    "    # 数据文件\n",
    "    datafile = './work/mnist.json.gz'\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\n",
    "    data = json.load(gzip.open(datafile))\n",
    "    train_set, val_set, eval_set = data\n",
    "\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\n",
    "    IMG_ROWS = 28\n",
    "    IMG_COLS = 28\n",
    "\n",
    "    if mode == 'train':\n",
    "        imgs = train_set[0]\n",
    "        labels = train_set[1]\n",
    "    elif mode == 'valid':\n",
    "        imgs = val_set[0]\n",
    "        labels = val_set[1]\n",
    "    elif mode == 'eval':\n",
    "        imgs = eval_set[0]\n",
    "        labels = eval_set[1]\n",
    "\n",
    "    imgs_length = len(imgs)\n",
    "\n",
    "    assert len(imgs) == len(labels), \\\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\n",
    "                  len(imgs), len(labels))\n",
    "\n",
    "    index_list = list(range(imgs_length))\n",
    "\n",
    "    # 读入数据时用到的batchsize\n",
    "    BATCHSIZE = 100\n",
    "\n",
    "    # 定义数据生成器\n",
    "    def data_generator():\n",
    "        if mode == 'train':\n",
    "            random.shuffle(index_list)\n",
    "        imgs_list = []\n",
    "        labels_list = []\n",
    "        for i in index_list:\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\n",
    "            label = np.reshape(labels[i], [1]).astype('float32')\n",
    "            imgs_list.append(img) \n",
    "            labels_list.append(label)\n",
    "            if len(imgs_list) == BATCHSIZE:\n",
    "                yield np.array(imgs_list), np.array(labels_list)\n",
    "                imgs_list = []\n",
    "                labels_list = []\n",
    "\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\n",
    "        if len(imgs_list) > 0:\n",
    "            yield np.array(imgs_list), np.array(labels_list)\n",
    "\n",
    "    return data_generator\n",
    "# 多层卷积神经网络实现\n",
    "class MNIST(fluid.dygraph.Layer):\n",
    "     def __init__(self, name_scope):\n",
    "         super(MNIST, self).__init__(name_scope)\n",
    "         \n",
    "         # 定义卷积层，输出特征通道num_filters设置为20，卷积核的大小filter_size为5，卷积步长stride=1，padding=2\n",
    "         # 激活函数使用relu\n",
    "         self.conv1 = Conv2D(num_channels=1, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义池化层，池化核pool_size=2，池化步长为2，选择最大池化方式\n",
    "         self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='avg')\n",
    "         # 定义卷积层，输出特征通道num_filters设置为20，卷积核的大小filter_size为5，卷积步长stride=1，padding=2\n",
    "         self.conv2 = Conv2D(num_channels=20, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\n",
    "         # 定义池化层，池化核pool_size=2，池化步长为2，选择最大池化方式\n",
    "         self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\n",
    "         # 定义一层全连接层，输出维度是1，不使用激活函数\n",
    "         self.fc = Linear(input_dim=980, output_dim=1, act=None)\n",
    "         \n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\n",
    "     def forward(self, inputs):\n",
    "         x = self.conv1(inputs)\n",
    "         x = self.pool1(x)\n",
    "         x = self.conv2(x)\n",
    "         x = self.pool2(x)\n",
    "         x = fluid.layers.reshape(x, [x.shape[0], -1])\n",
    "         x = self.fc(x)\n",
    "         return x\n",
    "\n",
    "start = time()\n",
    "#网络结构部分之后的代码，保持不变\n",
    "with fluid.dygraph.guard(fluid.CPUPlace()):\n",
    "    model = MNIST(\"mnist\")\n",
    "    model.train()\n",
    "    #调用加载数据的函数\n",
    "    train_loader = load_data('train')\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\n",
    "    EPOCH_NUM = 5\n",
    "    for epoch_id in range(EPOCH_NUM):\n",
    "        for batch_id, data in enumerate(train_loader()):\n",
    "            #准备数据\n",
    "            image_data, label_data = data\n",
    "            image = fluid.dygraph.to_variable(image_data)\n",
    "            label = fluid.dygraph.to_variable(label_data)\n",
    "             \n",
    "            #前向计算的过程\n",
    "            predict = model(image)\n",
    "            \n",
    "            #计算损失，取一个批次样本损失的平均值\n",
    "            loss = fluid.layers.square_error_cost(predict, label)\n",
    "            avg_loss = fluid.layers.mean(loss)\n",
    "            \n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\n",
    "            if batch_id % 200 == 0:\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\n",
    "            \n",
    "            #后向传播，更新参数的过程\n",
    "            avg_loss.backward()\n",
    "            optimizer.minimize(avg_loss)\n",
    "            model.clear_gradients()\n",
    "\n",
    "    #保存模型参数\n",
    "    end = time()\n",
    "    print('Time', end-start)\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading mnist dataset from ./work/mnist.json.gz ......\n",
      "epoch: 0, batch: 0, loss is: [26.254694]\n",
      "epoch: 0, batch: 200, loss is: [4.2599707]\n",
      "epoch: 0, batch: 400, loss is: [1.9664823]\n",
      "epoch: 1, batch: 0, loss is: [2.347371]\n",
      "epoch: 1, batch: 200, loss is: [1.6247109]\n",
      "epoch: 1, batch: 400, loss is: [1.5282687]\n",
      "epoch: 2, batch: 0, loss is: [1.0661851]\n",
      "epoch: 2, batch: 200, loss is: [1.0829281]\n",
      "epoch: 2, batch: 400, loss is: [1.0544606]\n",
      "epoch: 3, batch: 0, loss is: [0.98082364]\n",
      "epoch: 3, batch: 200, loss is: [1.277382]\n",
      "epoch: 3, batch: 400, loss is: [1.2035968]\n",
      "epoch: 4, batch: 0, loss is: [1.6488369]\n",
      "epoch: 4, batch: 200, loss is: [1.179404]\n",
      "epoch: 4, batch: 400, loss is: [1.3868287]\n",
      "Time 28.782493352890015\n"
     ]
    }
   ],
   "source": [
    "#2 学习视频，修改以下代码使其能正常执行（部分代码缺失），并修改卷积核个数，或者增加卷积层树，修改激活函数等方式找到你认为最合适的超参\r\n",
    "#2.2 修改代码使其能在GPU上执行，并比较与CPU上执行的时间差异\r\n",
    "import os\r\n",
    "import random\r\n",
    "import paddle\r\n",
    "import paddle.fluid as fluid\r\n",
    "from paddle.fluid.dygraph.nn import Conv2D, Pool2D, Linear\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from PIL import Image\r\n",
    "from time import *\r\n",
    "\r\n",
    "import gzip\r\n",
    "import json\r\n",
    "\r\n",
    "# 定义数据集读取器\r\n",
    "def load_data(mode='train'):\r\n",
    "\r\n",
    "    # 数据文件\r\n",
    "    datafile = './work/mnist.json.gz'\r\n",
    "    print('loading mnist dataset from {} ......'.format(datafile))\r\n",
    "    data = json.load(gzip.open(datafile))\r\n",
    "    train_set, val_set, eval_set = data\r\n",
    "\r\n",
    "    # 数据集相关参数，图片高度IMG_ROWS, 图片宽度IMG_COLS\r\n",
    "    IMG_ROWS = 28\r\n",
    "    IMG_COLS = 28\r\n",
    "\r\n",
    "    if mode == 'train':\r\n",
    "        imgs = train_set[0]\r\n",
    "        labels = train_set[1]\r\n",
    "    elif mode == 'valid':\r\n",
    "        imgs = val_set[0]\r\n",
    "        labels = val_set[1]\r\n",
    "    elif mode == 'eval':\r\n",
    "        imgs = eval_set[0]\r\n",
    "        labels = eval_set[1]\r\n",
    "\r\n",
    "    imgs_length = len(imgs)\r\n",
    "\r\n",
    "    assert len(imgs) == len(labels), \\\r\n",
    "          \"length of train_imgs({}) should be the same as train_labels({})\".format(\r\n",
    "                  len(imgs), len(labels))\r\n",
    "\r\n",
    "    index_list = list(range(imgs_length))\r\n",
    "\r\n",
    "    # 读入数据时用到的batchsize\r\n",
    "    BATCHSIZE = 100\r\n",
    "\r\n",
    "    # 定义数据生成器\r\n",
    "    def data_generator():\r\n",
    "        if mode == 'train':\r\n",
    "            random.shuffle(index_list)\r\n",
    "        imgs_list = []\r\n",
    "        labels_list = []\r\n",
    "        for i in index_list:\r\n",
    "            img = np.reshape(imgs[i], [1, IMG_ROWS, IMG_COLS]).astype('float32')\r\n",
    "            label = np.reshape(labels[i], [1]).astype('float32')\r\n",
    "            imgs_list.append(img) \r\n",
    "            labels_list.append(label)\r\n",
    "            if len(imgs_list) == BATCHSIZE:\r\n",
    "                yield np.array(imgs_list), np.array(labels_list)\r\n",
    "                imgs_list = []\r\n",
    "                labels_list = []\r\n",
    "\r\n",
    "        # 如果剩余数据的数目小于BATCHSIZE，\r\n",
    "        # 则剩余数据一起构成一个大小为len(imgs_list)的mini-batch\r\n",
    "        if len(imgs_list) > 0:\r\n",
    "            yield np.array(imgs_list), np.array(labels_list)\r\n",
    "\r\n",
    "    return data_generator\r\n",
    "# 多层卷积神经网络实现\r\n",
    "class MNIST(fluid.dygraph.Layer):\r\n",
    "     def __init__(self, name_scope):\r\n",
    "         super(MNIST, self).__init__(name_scope)\r\n",
    "         \r\n",
    "         # 定义卷积层，输出特征通道num_filters设置为20，卷积核的大小filter_size为5，卷积步长stride=1，padding=2\r\n",
    "         # 激活函数使用relu\r\n",
    "         self.conv1 = Conv2D(num_channels=1, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\r\n",
    "         # 定义池化层，池化核pool_size=2，池化步长为2，选择最大池化方式\r\n",
    "         self.pool1 = Pool2D(pool_size=2, pool_stride=2, pool_type='avg')\r\n",
    "         # 定义卷积层，输出特征通道num_filters设置为20，卷积核的大小filter_size为5，卷积步长stride=1，padding=2\r\n",
    "         self.conv2 = Conv2D(num_channels=20, num_filters=20, filter_size=5, stride=1, padding=2, act='relu')\r\n",
    "         # 定义池化层，池化核pool_size=2，池化步长为2，选择最大池化方式\r\n",
    "         self.pool2 = Pool2D(pool_size=2, pool_stride=2, pool_type='max')\r\n",
    "         # 定义一层全连接层，输出维度是1，不使用激活函数\r\n",
    "         self.fc = Linear(input_dim=980, output_dim=1, act=None)\r\n",
    "         \r\n",
    "    # 定义网络前向计算过程，卷积后紧接着使用池化层，最后使用全连接层计算最终输出\r\n",
    "     def forward(self, inputs):\r\n",
    "         x = self.conv1(inputs)\r\n",
    "         x = self.pool1(x)\r\n",
    "         x = self.conv2(x)\r\n",
    "         x = self.pool2(x)\r\n",
    "         x = fluid.layers.reshape(x, [x.shape[0], -1])\r\n",
    "         x = self.fc(x)\r\n",
    "         return x\r\n",
    "\r\n",
    "start = time()\r\n",
    "#网络结构部分之后的代码，保持不变\r\n",
    "with fluid.dygraph.guard(fluid.CUDAPlace(0)):\r\n",
    "    model = MNIST(\"mnist\")\r\n",
    "    model.train()\r\n",
    "    #调用加载数据的函数\r\n",
    "    train_loader = load_data('train')\r\n",
    "    optimizer = fluid.optimizer.SGDOptimizer(learning_rate=0.01, parameter_list=model.parameters())\r\n",
    "    EPOCH_NUM = 5\r\n",
    "    for epoch_id in range(EPOCH_NUM):\r\n",
    "        for batch_id, data in enumerate(train_loader()):\r\n",
    "            #准备数据\r\n",
    "            image_data, label_data = data\r\n",
    "            image = fluid.dygraph.to_variable(image_data)\r\n",
    "            label = fluid.dygraph.to_variable(label_data)\r\n",
    "             \r\n",
    "            #前向计算的过程\r\n",
    "            predict = model(image)\r\n",
    "            \r\n",
    "            #计算损失，取一个批次样本损失的平均值\r\n",
    "            loss = fluid.layers.square_error_cost(predict, label)\r\n",
    "            avg_loss = fluid.layers.mean(loss)\r\n",
    "            \r\n",
    "            #每训练了100批次的数据，打印下当前Loss的情况\r\n",
    "            if batch_id % 200 == 0:\r\n",
    "                print(\"epoch: {}, batch: {}, loss is: {}\".format(epoch_id, batch_id, avg_loss.numpy()))\r\n",
    "            \r\n",
    "            #后向传播，更新参数的过程\r\n",
    "            avg_loss.backward()\r\n",
    "            optimizer.minimize(avg_loss)\r\n",
    "            model.clear_gradients()\r\n",
    "\r\n",
    "    #保存模型参数\r\n",
    "    end = time()\r\n",
    "    print('Time', end-start)\r\n",
    "    fluid.save_dygraph(model.state_dict(), 'mnist')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PaddlePaddle 1.7.0 (Python 3.5)",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
